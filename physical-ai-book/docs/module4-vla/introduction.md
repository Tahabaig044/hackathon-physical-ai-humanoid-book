---
sidebar_position: 1
---

# Introduction to Vision-Language-Action (VLA)

This module introduces Vision-Language-Action (VLA) models, which combine visual perception, language understanding, and action planning for robotics applications.

## Overview

VLA models enable robots to understand natural language commands and perform complex tasks in real-world environments.

## Applications

- Household robotics
- Industrial automation
- Assistive robotics